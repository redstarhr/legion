// legion/chat_gpt_bot/interactions/modals/submitGptConfig.js
const { MessageFlags } = require('discord.js');
const { isChatGptAdmin } = require('../../../permissionManager');
const { setChatGPTConfig } = require('../../utils/configManager');
const { gptConfigModal, gptSystemPromptInput, gptTemperatureInput, gptModelInput } = require('../../utils/customIds');
const { handleInteractionError } = require('../../../utils/interactionErrorLogger');

module.exports = {
    customId: gptConfigModal,
    async handle(interaction) {
        try {
            await interaction.deferReply({ flags: MessageFlags.Ephemeral });

            if (!(await isChatGptAdmin(interaction))) {
                return interaction.editReply({ content: 'ğŸš« ã“ã®æ“ä½œã‚’å®Ÿè¡Œã™ã‚‹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚' });
            }

            const systemPrompt = interaction.fields.getTextInputValue(gptSystemPromptInput) || null;
            const temperatureRaw = interaction.fields.getTextInputValue(gptTemperatureInput);
            const model = interaction.fields.getTextInputValue(gptModelInput) || null;

            const updates = { systemPrompt, model };

            if (temperatureRaw) {
                const temperature = parseFloat(temperatureRaw);
                if (isNaN(temperature) || temperature < 0.0 || temperature > 2.0) {
                    return interaction.editReply({ content: 'âš ï¸ ã€ŒTemperatureã€ã«ã¯0.0ã‹ã‚‰2.0ã¾ã§ã®æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚' });
                }
                updates.temperature = temperature;
            } else {
                updates.temperature = null;
            }

            await setChatGPTConfig(interaction.guildId, updates);

            await interaction.editReply({ content: 'âœ… ChatGPTã®åŸºæœ¬è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚\nå†åº¦ `/legion_chatgpt_è¨­å®š è¡¨ç¤º` ã‚’å®Ÿè¡Œã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚' });

        } catch (error) {
            await handleInteractionError({ interaction, error, context: 'ChatGPTåŸºæœ¬è¨­å®šä¿å­˜' });
        }
    }
};